# DSOCR-HW: DeepSeek-OCR Handwriting Fine-tuning

**–ü—Ä–æ–µ–∫—Ç –¥–ª—è fine-tuning DeepSeek-OCR –Ω–∞ —Ä—É–∫–æ–ø–∏—Å–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LoRA**

## –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–°–æ–∑–¥–∞—Ç—å –ª—ë–≥–∫–∏–π LoRA-–∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ DeepSeek-OCR, –∫–æ—Ç–æ—Ä—ã–π –æ–±—É—á–µ–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å **–ª–∏—á–Ω—ã–µ —Ä—É–∫–æ–ø–∏—Å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã** (–∑–∞–º–µ—Ç–∫–∏, –∞—Ä—Ö–∏–≤—ã, —Ñ–æ—Ä–º—ã). –≠—Ç–æ—Ç –∞–¥–∞–ø—Ç–µ—Ä —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á–∏, –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º OCR-—Å–∏—Å—Ç–µ–º–∞–º (Tesseract), –∫–æ—Ç–æ—Ä—ã–µ –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞—é—Ç —Å —Ä—É–∫–æ–ø–∏—Å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º.

## –ö–æ–º–∞–Ω–¥–∞

- **–í–ª–∞–¥–∏–º–∏—Ä** (Product Owner) ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∑–∞–¥–∞—á–∏, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–≤—å—é
- **–°–µ–º—ë–Ω "–°—ë–º–∞"** (Tech Lead) ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è, code review, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- **–ù–∏–∫–æ–ª–∞–π** (Senior ML Engineer, Cursor AI) ‚Äî –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤, fine-tuning, —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

## –ñ–µ–ª–µ–∑–æ –∏ –æ–∫—Ä—É–∂–µ–Ω–∏–µ

- **GPU**: NVIDIA GeForce RTX 5060 Ti 16 –ì–ë (CUDA Capability sm_120)
- **OS**: Windows 10
- **Python**: 3.10+ (–≤ venv)
- **PyTorch**: 2.9.1+cu128 (–¥–ª—è RTX 5060 Ti)
- **IDE**: Cursor AI

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
DSOCR-HW/
‚îú‚îÄ‚îÄ data/                          # –î–∞—Ç–∞—Å–µ—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # –°—ã—Ä—ã–µ —Å–∫–∞–Ω—ã —Ä—É–∫–æ–ø–∏—Å–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ annotated/                 # –†–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (annotations.csv)
‚îÇ   ‚îî‚îÄ‚îÄ processed/                 # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
‚îÇ       ‚îú‚îÄ‚îÄ train/
‚îÇ       ‚îî‚îÄ‚îÄ val/
‚îú‚îÄ‚îÄ models/                        # –ú–æ–¥–µ–ª–∏ –∏ –∞–¥–∞–ø—Ç–µ—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ base/                      # –ë–∞–∑–æ–≤–∞—è DeepSeek-OCR (–∫—ç—à HuggingFace)
‚îÇ   ‚îî‚îÄ‚îÄ lora_adapters/             # –ù–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LoRA
‚îÇ       ‚îî‚îÄ‚îÄ handwriting_v1/
‚îú‚îÄ‚îÄ scripts/                       # –°–∫—Ä–∏–ø—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ prepare_dataset.py         # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ train_lora.py              # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ LoRA
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                # –û—Ü–µ–Ω–∫–∞ CER/WER
‚îÇ   ‚îî‚îÄ‚îÄ inference.py               # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Å LoRA
‚îú‚îÄ‚îÄ utils/                         # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ image_processor.py         # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îú‚îÄ‚îÄ configs/                       # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ training_config.yaml       # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ inference_config.yaml      # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
‚îú‚îÄ‚îÄ logs/                          # –õ–æ–≥–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ –∏ –æ—à–∏–±–æ–∫
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ .cursorrules                   # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è Cursor AI (–ù–∏–∫–æ–ª–∞–π)
‚îú‚îÄ‚îÄ requirements.txt               # Python –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ .gitignore                     # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ñ–∞–π–ª—ã
‚îî‚îÄ‚îÄ README.md                      # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è –ù–∏–∫–æ–ª–∞—è (Cursor AI)

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```powershell
cd C:\
git clone https://github.com/mrbp-20/DSOCR-HW.git
cd DSOCR-HW
```

### 2. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
```

### 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```powershell
pip install -r requirements.txt
```

**–í–∞–∂–Ω–æ**: –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å Flash Attention (–¥–ª—è sm_120), –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `attn_implementation="eager"` –≤ –∫–æ–Ω—Ñ–∏–≥–µ –º–æ–¥–µ–ª–∏.

### 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```powershell
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A"}')"
```

–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
PyTorch: 2.9.1+cu128
CUDA available: True
CUDA version: 12.8
GPU: NVIDIA GeForce RTX 5060 Ti
```

### 5. –û—Ç–∫—Ä—ã—Ç—å –≤ Cursor

```powershell
cursor .
```

–ö–æ–≥–¥–∞ Cursor –æ—Ç–∫—Ä–æ–µ—Ç—Å—è, –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—á–∏—Ç–∞–µ—Ç `.cursorrules` –∏ –±—É–¥–µ—Ç –∑–Ω–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞.

## Roadmap (Issues)

- **Issue #1**: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (`prepare_dataset.py`) ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞, –≤–∞–ª–∏–¥–∞—Ü–∏—è, split
- **Issue #2**: Fine-tuning —Å–∫—Ä–∏–ø—Ç (`train_lora.py`) ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA, training loop
- **Issue #3**: Evaluation —Å–∫—Ä–∏–ø—Ç (`evaluate.py`) ‚Äî –º–µ—Ç—Ä–∏–∫–∏ CER/WER
- **Issue #4**: Inference —Å–∫—Ä–∏–ø—Ç (`inference.py`) ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ä—É–∫–æ–ø–∏—Å–µ–π
- **Issue #5**: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

## Workflow

1. **–í–ª–∞–¥–∏–º–∏—Ä** —Å–∫–∞–Ω–∏—Ä—É–µ—Ç —Ä—É–∫–æ–ø–∏—Å–∏ ‚Üí `data/raw/`
2. **–í–ª–∞–¥–∏–º–∏—Ä** —Ä–∞–∑–º–µ—á–∞–µ—Ç ‚Üí `data/annotated/annotations.csv`
3. **–ù–∏–∫–æ–ª–∞–π** –ø–∏—à–µ—Ç —Å–∫—Ä–∏–ø—Ç—ã ‚Üí Pull Request ‚Üí **–°–µ–º—ë–Ω** —Ä–µ–≤—å—é–∏—Ç ‚Üí –º–µ—Ä–∂
4. **–ù–∏–∫–æ–ª–∞–π** –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É ‚Üí –Ω–æ—á—å –Ω–∞ GPU ‚Üí —É—Ç—Ä–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
5. **–í–ª–∞–¥–∏–º–∏—Ä** —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç ‚Üí feedback ‚Üí –∏—Ç–µ—Ä–∞—Ü–∏–∏

## –í–∞–∂–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
```powershell
python scripts/prepare_dataset.py --input data/raw --annotations data/annotated/annotations.csv --output data/processed
```

### –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ LoRA
```powershell
python scripts/train_lora.py --config configs/training_config.yaml
```

### Evaluation
```powershell
python scripts/evaluate.py --model models/lora_adapters/handwriting_v1 --test data/processed/val
```

### Inference
```powershell
python scripts/inference.py --model models/lora_adapters/handwriting_v1 --input path/to/handwriting.jpg
```

## –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ `logs/`:
- `logs/training_YYYYMMDD_HHMMSS.log` ‚Äî –ª–æ–≥–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
- `logs/errors_YYYYMMDD_HHMMSS.log` ‚Äî –æ—à–∏–±–∫–∏
- `logs/inference_YYYYMMDD_HHMMSS.log` ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

- **CER (Character Error Rate)**: % –æ—à–∏–±–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
  - CER < 10% ‚Äî —Ö–æ—Ä–æ—à–æ
  - CER < 5% ‚Äî –æ—Ç–ª–∏—á–Ω–æ
- **WER (Word Error Rate)**: % –æ—à–∏–±–æ—á–Ω—ã—Ö —Å–ª–æ–≤

## Troubleshooting

### Flash Attention –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è

–í `configs/training_config.yaml` –∏ `configs/inference_config.yaml` —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å:
```yaml
model:
  attn_implementation: "eager"  # –≤–º–µ—Å—Ç–æ "flash_attention_2"
```

### CUDA out of memory

–£–º–µ–Ω—å—à–∏—Ç—å `batch_size` –≤ `configs/training_config.yaml`:
```yaml
training:
  batch_size: 2  # –≤–º–µ—Å—Ç–æ 4
```

### PyTorch –Ω–µ –≤–∏–¥–∏—Ç GPU

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å NVIDIA Driver –∏ CUDA Toolkit:
```powershell
nvidia-smi
nvcc --version
```

## –°—Å—ã–ª–∫–∏

- [DeepSeek-OCR –Ω–∞ HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- [PEFT (LoRA) –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://huggingface.co/docs/peft)
- [Unsloth –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è fine-tuning](https://github.com/unslothai/unsloth)

## –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

**–°–æ–∑–¥–∞–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π Dream Team: –í–ª–∞–¥–∏–º–∏—Ä, –°–µ–º—ë–Ω, –ù–∏–∫–æ–ª–∞–π** üöÄ
