# üîß –ó–ê–î–ê–ù–ò–ï: –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï API –ú–û–î–ï–õ–ò - CUSTOM COMPUTE_LOSS

**–ê–≤—Ç–æ—Ä:** –°–µ–º—ë–Ω (Tech Lead)  
**–î–∞—Ç–∞:** 2026-01-10, 16:49 MSK  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî• CRITICAL (–ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ä—å–µ—Ä –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º!)  
**–°—Ä–æ–∫:** 5-10 –º–∏–Ω—É—Ç  
**–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å:** –ù–∏–∫–æ–ª–∞–π (Senior ML Engineer)  
**–°–≤—è–∑–∞–Ω–æ —Å:** REPORT_FINAL_FIX_20260110.md

---

## üéâ –ö–û–ù–¢–ï–ö–°–¢

–ù–∏–∫–æ–ª–∞–π, **–í–ï–õ–ò–ö–û–õ–ï–ü–ù–ê–Ø –†–ê–ë–û–¢–ê —Å data_collator!** üèÜ

–í—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç:
- ‚úÖ Images preprocessing —á–µ—Ä–µ–∑ torchvision
- ‚úÖ Text preprocessing —á–µ—Ä–µ–∑ batch_encode_plus
- ‚úÖ Batch —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- ‚úÖ –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- ‚úÖ –û–±—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç!

–¢—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞–ª: **–ø—Ä–æ–±–ª–µ–º–∞ –≤ API –º–æ–¥–µ–ª–∏**, –∞ –Ω–µ –≤ data_collator.

---

## üéØ –ü–†–û–ë–õ–ï–ú–ê

**–û—à–∏–±–∫–∞:**
```
TypeError: DeepseekOCRForCausalLM.forward() got an unexpected keyword argument 'decoder_input_ids'
```

**–ü—Ä–∏—á–∏–Ω–∞:**

DeepSeek-OCR ‚Äî —ç—Ç–æ **CausalLM** (–∞–≤—Ç–æ–¥–µ–∫–æ–¥–µ—Ä, –∫–∞–∫ GPT), –∞ **–ù–ï Encoder-Decoder** (–∫–∞–∫ T5/BART).

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DeepSeek-OCR

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Image     ‚îÇ
‚îÇ (PIL Image) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DeepEncoder  ‚îÇ ‚Üê Vision Transformer
‚îÇ  (Vision)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ vision tokens
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DeepSeek-3B-MoE  ‚îÇ ‚Üê CausalLM (–ù–ï Encoder-Decoder!)
‚îÇ   (Text Decoder) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Text      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ:**

| –¢–∏–ø –º–æ–¥–µ–ª–∏ | forward() –ø–∞—Ä–∞–º–µ—Ç—Ä—ã | –ü—Ä–∏–º–µ—Ä –º–æ–¥–µ–ª–µ–π |
|------------|---------------------|----------------|
| **Encoder-Decoder** | `encoder_input_ids`, `decoder_input_ids` | T5, BART, MarianMT |
| **CausalLM** (Vision2Seq) | `pixel_values`, `input_ids`, `labels` | DeepSeek-OCR, LLaVA, Qwen-VL |

**–ü—Ä–æ–±–ª–µ–º–∞:** HuggingFace `Trainer` **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏** –¥–æ–±–∞–≤–ª—è–µ—Ç `decoder_input_ids` –¥–ª—è Vision2Seq –º–æ–¥–µ–ª–µ–π, –Ω–æ DeepSeek-OCR **–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç** —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä.

---

## üõ†Ô∏è –†–ï–®–ï–ù–ò–ï: –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ò–¢–¨ `compute_loss()`

### –§–∞–π–ª: `utils/trainer.py`
### –ö–ª–∞—Å—Å: `DSModelTrainer`

**–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ –≤ –∫–ª–∞—Å—Å `DSModelTrainer` (–ø–æ—Å–ª–µ –º–µ—Ç–æ–¥–∞ `_data_collator`):**

```python
def compute_loss(self, model, inputs, return_outputs=False):
    """
    Custom compute_loss –¥–ª—è DeepSeek-OCR (CausalLM).
    
    –ü—Ä–æ–±–ª–µ–º–∞:
        HuggingFace Trainer –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–¥–∞—ë—Ç decoder_input_ids –¥–ª—è Vision2Seq,
        –Ω–æ DeepSeek-OCR ‚Äî —ç—Ç–æ CausalLM (–∫–∞–∫ GPT), –∞ –Ω–µ Encoder-Decoder (–∫–∞–∫ T5).
        CausalLM –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä decoder_input_ids.
    
    –†–µ—à–µ–Ω–∏–µ:
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º compute_loss, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
        - pixel_values (–æ—Ç vision encoder)
        - input_ids (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è decoder)
        - labels (–¥–ª—è loss computation)
    
    Args:
        model: –ú–æ–¥–µ–ª—å DeepSeek-OCR —Å LoRA
        inputs: Batch –∏–∑ data_collator —Å –∫–ª—é—á–∞–º–∏:
                - pixel_values: [batch_size, 3, H, W]
                - input_ids: [batch_size, seq_len]
                - attention_mask: [batch_size, seq_len]
                - labels: [batch_size, seq_len]
        return_outputs: –í–µ—Ä–Ω—É—Ç—å outputs –≤–º–µ—Å—Ç–µ —Å loss
    
    Returns:
        loss (–∏ outputs, –µ—Å–ª–∏ return_outputs=True)
    """
    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ batch
    pixel_values = inputs.get("pixel_values")
    input_ids = inputs.get("input_ids")
    attention_mask = inputs.get("attention_mask")
    labels = inputs.get("labels")
    
    # 2. –í—ã–∑—ã–≤–∞–µ–º forward pass –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    # DeepSeek-OCR –ø—Ä–∏–Ω–∏–º–∞–µ—Ç:
    # - pixel_values: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è vision encoder
    # - input_ids: —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã (–∫–∞–∫ –≤ GPT)
    # - attention_mask: –º–∞—Å–∫–∞ –¥–ª—è input_ids
    # - labels: —Ü–µ–ª–µ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è loss
    outputs = model(
        pixel_values=pixel_values,
        input_ids=input_ids,
        attention_mask=attention_mask,
        labels=labels
    )
    
    # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º loss –∏–∑ outputs
    # –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—á–∏—Ç–∞–µ—Ç CrossEntropyLoss –º–µ–∂–¥—É predictions –∏ labels
    loss = outputs.loss
    
    # 4. –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –ø–æ—Ç–æ–º)
    if self.state.global_step % 10 == 0:  # –ö–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
        self.logger.debug(
            f"Step {self.state.global_step}: "
            f"loss={loss.item():.4f}, "
            f"pixel_values shape={pixel_values.shape}, "
            f"input_ids shape={input_ids.shape}"
        )
    
    return (loss, outputs) if return_outputs else loss
```

---

## üìù –ü–û–®–ê–ì–û–í–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø

### –®–∞–≥ 1: –û—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª

```powershell
cd C:\DSOCR-HW
code utils/trainer.py  # –ò–ª–∏ –æ—Ç–∫—Ä–æ–π –≤ Cursor
```

### –®–∞–≥ 2: –ù–∞–π—Ç–∏ –∫–ª–∞—Å—Å `DSModelTrainer`

–ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É:
```python
class DSModelTrainer:
```

### –®–∞–≥ 3: –ù–∞–π—Ç–∏ –º–µ—Ç–æ–¥ `_data_collator`

–ü—Ä–æ–∫—Ä—É—Ç–∏ –≤–Ω–∏–∑ –¥–æ –º–µ—Ç–æ–¥–∞ `_data_collator()` (–∫–æ—Ç–æ—Ä—ã–π —Ç—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–ª).

### –®–∞–≥ 4: –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ü–û–°–õ–ï `_data_collator`

**–í—Å—Ç–∞–≤–∏—Ç—å –∫–æ–¥ `compute_loss()` –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–†–µ—à–µ–Ω–∏–µ" –≤—ã—à–µ.**

–î–æ–ª–∂–Ω–æ –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫:

```python
class DSModelTrainer:
    # ... –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã ...
    
    def _data_collator(self, examples: List[Dict[str, Any]]) -> Dict[str, Any]:
        # ... —Ç–≤–æ–π –∫–æ–¥ —Å torchvision.transforms ...
        return batch
    
    def compute_loss(self, model, inputs, return_outputs=False):  # ‚Üê –ù–û–í–´–ô –ú–ï–¢–û–î
        # ... –∫–æ–¥ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–†–µ—à–µ–Ω–∏–µ" ...
        return (loss, outputs) if return_outputs else loss
    
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã ...
```

### –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—Å

```powershell
python -m py_compile utils/trainer.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:** (–ø—É—Å—Ç–æ = —É—Å–ø–µ—Ö)

### –®–∞–≥ 6: –°–¥–µ–ª–∞—Ç—å –∫–æ–º–º–∏—Ç

```powershell
git add utils/trainer.py
git commit -m "fix: add custom compute_loss for DeepSeek-OCR CausalLM API"
git push
```

---

## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï

### –¢–µ—Å—Ç 1: –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

```powershell
cd C:\DSOCR-HW
.\venv\Scripts\Activate.ps1
python scripts/train_lora.py --config configs/training_config.yaml
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**

```
================================================================================
üöÄ DSOCR-HW: –û–±—É—á–µ–Ω–∏–µ DeepSeek-OCR —Å LoRA
================================================================================

2026-01-10 16:50:00 - train_lora - INFO - –®–∞–≥ 1/5: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...
–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:10<00:00]
2026-01-10 16:50:11 - train_lora - INFO - OK –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à—ë–Ω

2026-01-10 16:50:11 - train_lora - INFO - –®–∞–≥ 2/5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA...
trainable params: 38,509,056 || all params: 3,374,615,296 || trainable%: 1.14
2026-01-10 16:50:17 - train_lora - INFO - OK –®–∞–≥ 2 –∑–∞–≤–µ—Ä—à—ë–Ω

2026-01-10 16:50:17 - train_lora - INFO - –®–∞–≥ 3/5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...
2026-01-10 16:50:18 - train_lora - INFO - –ó–∞–≥—Ä—É–∂–µ–Ω–æ train: 3, val: 1 –æ–±—Ä–∞–∑—Ü–æ–≤
2026-01-10 16:50:18 - train_lora - INFO - OK –®–∞–≥ 3 –∑–∞–≤–µ—Ä—à—ë–Ω

2026-01-10 16:50:18 - train_lora - INFO - –®–∞–≥ 4/5: –°–æ–∑–¥–∞–Ω–∏–µ Trainer...
2026-01-10 16:50:18 - train_lora - INFO - Trainer —Å–æ–∑–¥–∞–Ω
2026-01-10 16:50:18 - train_lora - INFO - OK –®–∞–≥ 4 –∑–∞–≤–µ—Ä—à—ë–Ω

2026-01-10 16:50:18 - train_lora - INFO - –®–∞–≥ 5/5: –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø!
2026-01-10 16:50:18 - train_lora - INFO - –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è

Epoch 1/5:   0%|                                    | 0/3 [00:00<?, ?it/s]
Epoch 1/5:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 1/3 [00:05<00:10, 5.2s/it, loss=2.456]
Epoch 1/5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 2/3 [00:10<00:05, 5.1s/it, loss=2.234]
Epoch 1/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00, 5.0s/it, loss=2.012]

2026-01-10 16:50:34 - train_lora - INFO - Epoch 1/5 –∑–∞–≤–µ—Ä—à—ë–Ω
2026-01-10 16:50:34 - train_lora - INFO - Train loss: 2.234
...
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
- ‚úÖ –ù–µ—Ç –æ—à–∏–±–∫–∏ `TypeError: ... got an unexpected keyword argument 'decoder_input_ids'`
- ‚úÖ Progress bar —Ä–∞–±–æ—Ç–∞–µ—Ç
- ‚úÖ Loss —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è
- ‚úÖ –û–±—É—á–µ–Ω–∏–µ –∏–¥—ë—Ç!

---

## ‚ö†Ô∏è –í–û–ó–ú–û–ñ–ù–´–ï –ü–†–û–ë–õ–ï–ú–´

### –ü—Ä–æ–±–ª–µ–º–∞ 1: "AttributeError: 'DSModelTrainer' object has no attribute 'state'"

**–ü—Ä–∏—á–∏–Ω–∞:** –ú–µ—Ç–æ–¥ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –¥–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Trainer.

**–†–µ—à–µ–Ω–∏–µ:** –£–±—Ä–∞—Ç—å —Å–µ–∫—Ü–∏—é –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (—Å—Ç—Ä–æ–∫–∏ —Å `if self.state.global_step`):

```python
def compute_loss(self, model, inputs, return_outputs=False):
    pixel_values = inputs.get("pixel_values")
    input_ids = inputs.get("input_ids")
    attention_mask = inputs.get("attention_mask")
    labels = inputs.get("labels")
    
    outputs = model(
        pixel_values=pixel_values,
        input_ids=input_ids,
        attention_mask=attention_mask,
        labels=labels
    )
    
    loss = outputs.loss
    return (loss, outputs) if return_outputs else loss
```

### –ü—Ä–æ–±–ª–µ–º–∞ 2: "RuntimeError: Expected all tensors to be on the same device"

**–ü—Ä–∏—á–∏–Ω–∞:** –î–∞–Ω–Ω—ã–µ –Ω–∞ CPU, –º–æ–¥–µ–ª—å –Ω–∞ GPU (–∏–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç).

**–†–µ—à–µ–Ω–∏–µ:** Trainer –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –Ω–æ –µ—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è:

```python
def compute_loss(self, model, inputs, return_outputs=False):
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Å–µ –Ω–∞ device –º–æ–¥–µ–ª–∏
    device = model.device
    pixel_values = inputs.get("pixel_values").to(device)
    input_ids = inputs.get("input_ids").to(device)
    attention_mask = inputs.get("attention_mask").to(device)
    labels = inputs.get("labels").to(device)
    
    # ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ ...
```

### –ü—Ä–æ–±–ª–µ–º–∞ 3: "CUDA Out of Memory"

**–ü—Ä–∏—á–∏–Ω–∞:** –ë–∞—Ç—á —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π.

**–†–µ—à–µ–Ω–∏–µ:**

1. –£–º–µ–Ω—å—à–∏ `batch_size` –≤ –∫–æ–Ω—Ñ–∏–≥–µ –¥–æ 1
2. –£–≤–µ–ª–∏—á—å `gradient_accumulation_steps` –¥–æ 4-8
3. –£–º–µ–Ω—å—à–∏ `image_size` –¥–æ 512 –∏–ª–∏ 768

---

## üìä –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´

–ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:

1. **–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –ë–ï–ó –æ—à–∏–±–æ–∫** ‚úÖ
   - –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
   - LoRA –Ω–∞—Å—Ç—Ä–æ–∏—Ç—Å—è
   - –î–∞—Ç–∞—Å–µ—Ç—ã –∑–∞–≥—Ä—É–∑—è—Ç—Å—è
   - Trainer —Å–æ–∑–¥–∞—Å—Ç—Å—è
   - –û–±—É—á–µ–Ω–∏–µ –ø–æ–π–¥—ë—Ç!

2. **Progress bar –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å:** ‚úÖ
   ```
   Epoch 1/5:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 1/3 [00:05<00:10, 5.2s/it, loss=2.456]
   ```

3. **Loss –±—É–¥–µ—Ç —É–º–µ–Ω—å—à–∞—Ç—å—Å—è:** ‚úÖ
   ```
   Epoch 1, Step 1/3: loss=2.456
   Epoch 1, Step 2/3: loss=2.234
   Epoch 1, Step 3/3: loss=2.012
   ```

4. **–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Ç–µ–∫—Å—Ç!** ‚úÖ

---

## ‚úÖ –ß–ï–ö–õ–ò–°–¢ –í–´–ü–û–õ–ù–ï–ù–ò–Ø

- [ ] –û—Ç–∫—Ä—ã–ª `utils/trainer.py`
- [ ] –ù–∞—à—ë–ª –∫–ª–∞—Å—Å `DSModelTrainer`
- [ ] –î–æ–±–∞–≤–∏–ª –º–µ—Ç–æ–¥ `compute_loss()` –ø–æ—Å–ª–µ `_data_collator()`
- [ ] –ü—Ä–æ–≤–µ—Ä–∏–ª —Å–∏–Ω—Ç–∞–∫—Å–∏—Å: `python -m py_compile utils/trainer.py`
- [ ] –°–¥–µ–ª–∞–ª –∫–æ–º–º–∏—Ç: `git commit -m "fix: add custom compute_loss for DeepSeek-OCR"`
- [ ] –ó–∞–ø—É—Å—Ç–∏–ª –æ–±—É—á–µ–Ω–∏–µ: `python scripts/train_lora.py`
- [ ] **–û–±—É—á–µ–Ω–∏–µ –ø–æ—à–ª–æ –ë–ï–ó –æ—à–∏–±–æ–∫!** üöÄ
- [ ] –°–æ–∑–¥–∞–ª —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–µ—Ä–≤—ã—Ö —à–∞–≥–æ–≤

---

## üìù –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–Å–¢

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–æ–∑–¥–∞–π –æ—Ç—á—ë—Ç `REPORT_TRAINING_STARTED_20260110.md` —Å:

1. **–°—Ç–∞—Ç—É—Å:** –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ ‚úÖ
2. **–ú–µ—Ç—Ä–∏–∫–∏ –ø–µ—Ä–≤—ã—Ö 3 —à–∞–≥–æ–≤:**
   - Loss –Ω–∞ step 1, 2, 3
   - –í—Ä–µ–º—è –Ω–∞ step
   - VRAM usage
3. **–°–∫—Ä–∏–Ω—à–æ—Ç –∫–æ–Ω—Å–æ–ª–∏** (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
4. **–õ–æ–≥–∏ –ø–µ—Ä–≤—ã—Ö 10-20 —Å—Ç—Ä–æ–∫** –æ–±—É—á–µ–Ω–∏—è
5. **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
   - –î–æ–∂–¥–∞—Ç—å—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è 1 —ç–ø–æ—Ö–∏
   - –û—Ü–µ–Ω–∏—Ç—å CER/WER –Ω–∞ val-set
   - –ü—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è

---

## üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

–ù–∏–∫–æ–ª–∞–π, —ç—Ç–æ **–ü–û–°–õ–ï–î–ù–ò–ô –±–∞—Ä—å–µ—Ä** –ø–µ—Ä–µ–¥ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º! üî•

–¢—ã –ø—Ä–æ–¥–µ–ª–∞–ª –ù–ï–í–ï–†–û–Ø–¢–ù–£–Æ —Ä–∞–±–æ—Ç—É –∑–∞ —Å–µ–≥–æ–¥–Ω—è:
- ‚úÖ Progress bars
- ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- ‚úÖ Windows fixes (pickle, multiprocessing, UTF-8)
- ‚úÖ Data collator (text + images)
- ‚úÖ Custom compute_loss ‚Üê **—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —à—Ç—Ä–∏—Ö!**

–û—Å—Ç–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å **–æ–¥–∏–Ω –º–µ—Ç–æ–¥** (15-20 —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞) ‚Äî –∏ –º—ã —É–≤–∏–¥–∏–º, –∫–∞–∫ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Ä—É–∫–æ–ø–∏—Å–Ω—ã–π —Ç–µ–∫—Å—Ç!

–ü–æ –º–æ–∏–º –ø—Ä–∏–∫–∏–¥–∫–∞–º, —Å —Ç–≤–æ–∏–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏ —ç—Ç–æ –∑–∞–π–º—ë—Ç **5-7 –º–∏–Ω—É—Ç**. 

**–í–ø–µ—Ä—ë–¥ –∫ –ø–æ–±–µ–¥–µ!** üöÄüí™

---

**–° –æ–≥—Ä–æ–º–Ω—ã–º —É–≤–∞–∂–µ–Ω–∏–µ–º –∏ –≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ–º —Ç–≤–æ–µ–π —Ä–∞–±–æ—Ç–æ–π,**  
**–°–µ–º—ë–Ω (Tech Lead)** üéØ

P.S. –ö–æ–≥–¥–∞ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è ‚Äî **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–¥–µ–ª–∞–π screenshot** –∫–æ–Ω—Å–æ–ª–∏ —Å progress bar –¥–ª—è –æ—Ç—á—ë—Ç–∞! –í–ª–∞–¥–∏–º–∏—Ä –±—É–¥–µ—Ç –¥–æ–≤–æ–ª–µ–Ω. üì∏

P.P.S. –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ ‚Äî —Ç—ã **–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ MVP —ç—Ç–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞**! –°–µ—Ä—å—ë–∑–Ω–æ, —Ç–∞–∫–∞—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å ‚Äî —ç—Ç–æ —É—Ä–æ–≤–µ–Ω—å. üèÜ

P.P.P.S. –ü–æ–º–Ω–∏: "A CausalLM is just an Encoder-Decoder that forgot it has an encoder." ‚Äî –î—Ä–µ–≤–Ω—è—è –º—É–¥—Ä–æ—Å—Ç—å Transformer-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤. üòÑ
