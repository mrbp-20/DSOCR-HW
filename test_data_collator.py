"""
–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ data_collator.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –†–∞–∑–¥–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É images –∏ text
2. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –±–∞—Ç—á–∞
3. –ö–æ–¥–∏—Ä–æ–≤–∫—É –≤—ã–≤–æ–¥–∞
"""

import sys
import torch
from pathlib import Path
from PIL import Image
from transformers import AutoProcessor

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows
if sys.platform == 'win32':
    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')

print("=" * 80)
print("üß™ –¢–ï–°–¢: Data Collator –¥–ª—è DeepSeek-OCR")
print("=" * 80)

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ processor
print("\n1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ processor...")
processor = AutoProcessor.from_pretrained(
    "deepseek-ai/DeepSeek-OCR",
    revision="9f30c71f441d010e5429c532364a86705536c53a",
    trust_remote_code=True
)
print(f"   –¢–∏–ø processor: {type(processor)}")
print(f"   –ï—Å—Ç—å tokenizer: {hasattr(processor, 'tokenizer')}")

# 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
print("\n2Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
test_images = list(Path("data/raw").glob("*.jpg"))[:2]  # –ë–µ—Ä—ë–º 2 –æ–±—Ä–∞–∑—Ü–∞
test_texts = [
    "–ú–∏–Ω–æ–≤–∞–ª–æ –ø–æ—á—Ç–∏ –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏–µ...",
    "–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!"
]

print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(test_images)}")
print(f"   –¢–µ–∫—Å—Ç–æ–≤: {len(test_texts)}")

# 3. –¢–µ—Å—Ç —Ä–∞–∑–¥–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
print("\n3Ô∏è‚É£ –¢–µ—Å—Ç —Ä–∞–∑–¥–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏...")

# 3a. –û–±—Ä–∞–±–æ—Ç–∫–∞ images —á–µ—Ä–µ–∑ torchvision.transforms
print("   3a. –û–±—Ä–∞–±–æ—Ç–∫–∞ images —á–µ—Ä–µ–∑ torchvision.transforms...")
try:
    import torchvision.transforms as transforms
    
    images = [Image.open(img).convert('RGB') for img in test_images]
    
    transform = transforms.Compose([
        transforms.Resize((1024, 1024)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])
    
    pixel_values = torch.stack([transform(img) for img in images])
    print(f"       ‚úÖ pixel_values shape: {pixel_values.shape}")
    print(f"       ‚úÖ pixel_values dtype: {pixel_values.dtype}")
    print(f"       ‚úÖ pixel_values range: [{pixel_values.min():.2f}, {pixel_values.max():.2f}]")
except Exception as e:
    print(f"       ‚ùå –û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()

# 3b. Text —á–µ—Ä–µ–∑ processor.batch_encode_plus
print("   3b. –û–±—Ä–∞–±–æ—Ç–∫–∞ text —á–µ—Ä–µ–∑ processor.batch_encode_plus...")
try:
    text_inputs = processor.batch_encode_plus(
        test_texts,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=512
    )
    print(f"       ‚úÖ input_ids shape: {text_inputs['input_ids'].shape}")
    print(f"       ‚úÖ attention_mask shape: {text_inputs['attention_mask'].shape}")
except Exception as e:
    print(f"       ‚ùå –û—à–∏–±–∫–∞: {e}")

# 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–∞
print("\n4Ô∏è‚É£ –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–∞...")
try:
    batch = {
        'pixel_values': pixel_values,
        'input_ids': text_inputs['input_ids'],
        'attention_mask': text_inputs['attention_mask'],
        'labels': text_inputs['input_ids'].clone()
    }
    
    print("   –ö–ª—é—á–∏ –±–∞—Ç—á–∞:")
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"     - {key}: shape {value.shape}, dtype {value.dtype}")
        else:
            print(f"     - {key}: {type(value)}")
except Exception as e:
    print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
print("\n5Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")
print("   –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç: –ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! üöÄ")
print("   Emoji: üí™ ‚úÖ ‚ùå üéØ")

print("\n" + "=" * 80)
print("‚úÖ –¢–ï–°–¢ –ó–ê–í–ï–†–®–Å–ù!")
print("=" * 80)
