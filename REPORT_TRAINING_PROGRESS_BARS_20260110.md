# üìä –û–¢–ß–Å–¢: –ü–†–û–ì–†–ï–°–° –ë–ê–†–´ –ò –ü–†–û–ë–õ–ï–ú–ê –° DATA_COLLATOR

**–ê–≤—Ç–æ—Ä:** –ù–∏–∫–æ–ª–∞–π (Senior ML Engineer)  
**–î–∞—Ç–∞:** 2026-01-10  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ Progress bars —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã, ‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å data_collator API  
**Issue:** #2 (–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ)  

---

## üéØ –í–´–ü–û–õ–ù–ï–ù–ù–ê–Ø –†–ê–ë–û–¢–ê

### 1. –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (‚úÖ –ó–ê–í–ï–†–®–ï–ù–û)

**–ó–∞–¥–∞–Ω–∏–µ:** TASK_ADD_PROGRESS_INDICATOR_20260110.md

**–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**

1. **–î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç `tqdm` –≤ `utils/trainer.py`**
   - –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω `from tqdm import tqdm`

2. **–î–æ–±–∞–≤–ª–µ–Ω progress bar –≤ `load_model_and_processor()`**
   - Progress bar —Å 2 —à–∞–≥–∞–º–∏ (–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä + –º–æ–¥–µ–ª—å)
   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞
   - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –¥–æ–ª–≥–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ (5-30 –º–∏–Ω—É—Ç)

3. **–î–æ–±–∞–≤–ª–µ–Ω progress bar –≤ `prepare_datasets()`**
   - Progress bar —Å 2 —à–∞–≥–∞–º–∏ (train + val metadata)
   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞

4. **–í–∫–ª—é—á—ë–Ω progress bar –¥–ª—è –æ–±—É—á–µ–Ω–∏—è**
   - –î–æ–±–∞–≤–ª–µ–Ω `disable_tqdm=False` –≤ `TrainingArguments`
   - –≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π tqdm –≤ HuggingFace Trainer

5. **–£–ª—É—á—à–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ `scripts/train_lora.py`**
   - –ù—É–º–µ—Ä–∞—Ü–∏—è —à–∞–≥–æ–≤ (1/5, 2/5, ...)
   - –í–∏–∑—É–∞–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –º–µ–∂–¥—É —à–∞–≥–∞–º–∏
   - –°–æ–æ–±—â–µ–Ω–∏—è –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Progress bars –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- ‚úÖ –í–∏–¥–Ω–æ –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (0% ‚Üí 50% ‚Üí 100%)
- ‚úÖ –í–∏–¥–Ω–æ –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- ‚úÖ –í–∏–¥–Ω–æ –Ω–∞—á–∞–ª–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è

---

## üîß –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´

### –ü—Ä–æ–±–ª–µ–º–∞ 1: –ü–∞—Ä–∞–º–µ—Ç—Ä `optimizer` –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û)

**–û—à–∏–±–∫–∞:**
```
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'optimizer'
```

**–ü—Ä–∏—á–∏–Ω–∞:**
–í `transformers 4.45.0` –ø–∞—Ä–∞–º–µ—Ç—Ä `optimizer` –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ `TrainingArguments`. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `adamw_torch`.

**–†–µ—à–µ–Ω–∏–µ:**
–£–¥–∞–ª—ë–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `optimizer` –∏–∑ `TrainingArguments`. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.

**–§–∞–π–ª—ã:**
- `utils/trainer.py` - —É–¥–∞–ª–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ `optimizer=optimization_config.get('optimizer', 'adamw_torch')`

---

### –ü—Ä–æ–±–ª–µ–º–∞ 2: Pickle error —Å –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π data_collator (‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û)

**–û—à–∏–±–∫–∞:**
```
AttributeError: Can't pickle local object 'LoRATrainer.create_trainer.<locals>.data_collator'
```

**–ü—Ä–∏—á–∏–Ω–∞:**
–õ–æ–∫–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è `data_collator` –≤–Ω—É—Ç—Ä–∏ –º–µ—Ç–æ–¥–∞ `create_trainer()` –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è multiprocessing –Ω–∞ Windows.

**–†–µ—à–µ–Ω–∏–µ:**
–ü–µ—Ä–µ–Ω—ë—Å `data_collator` –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Å–∞ `_data_collator()`. –¢–µ–ø–µ—Ä—å —ç—Ç–æ –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Å–∞, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω.

**–§–∞–π–ª—ã:**
- `utils/trainer.py` - —Å–æ–∑–¥–∞–Ω –º–µ—Ç–æ–¥ `_data_collator()` –∫–ª–∞—Å—Å–∞ `LoRATrainer`
- `utils/trainer.py` - —É–¥–∞–ª–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è `data_collator` –∏–∑ `create_trainer()`

---

### –ü—Ä–æ–±–ª–µ–º–∞ 3: Pickle error —Å custom code –º–æ–¥–µ–ª—å—é (‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û)

**–û—à–∏–±–∫–∞:**
```
_pickle.PicklingError: Can't pickle <class 'transformers_modules.deepseek-ai.DeepSeek-OCR...'>
```

**–ü—Ä–∏—á–∏–Ω–∞:**
Custom code –º–æ–¥–µ–ª–∏ (—Å `trust_remote_code=True`) –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω—ã –¥–ª—è multiprocessing –Ω–∞ Windows.

**–†–µ—à–µ–Ω–∏–µ:**
–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω `dataloader_num_workers: 0` –≤ –∫–æ–Ω—Ñ–∏–≥–µ. –≠—Ç–æ –æ—Ç–∫–ª—é—á–∞–µ—Ç multiprocessing –¥–ª—è DataLoader. –î–ª—è –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (3 train –æ–±—Ä–∞–∑—Ü–∞) —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ.

**–§–∞–π–ª—ã:**
- `configs/training_config.yaml` - –∏–∑–º–µ–Ω—ë–Ω `dataloader_num_workers: 2` ‚Üí `dataloader_num_workers: 0`

---

## ‚ùå –¢–ï–ö–£–©–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: DATA_COLLATOR API

### –û—à–∏–±–∫–∞

```
TypeError: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'images'
```

**–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:**
```
File "C:\DSOCR-HW\utils\trainer.py", line 206, in _data_collator
    inputs = self.processor(images=images, text=texts, return_tensors="pt", padding=True)
```

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ `_data_collator()`:**
```python
def _data_collator(self, examples: List[Dict[str, Any]]) -> Dict[str, Any]:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    images = [Image.open(ex['image_path']).convert('RGB') for ex in examples]
    texts = [ex['text'] for ex in examples]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ processor
    inputs = self.processor(images=images, text=texts, return_tensors="pt", padding=True)  # ‚Üê –û–®–ò–ë–ö–ê –ó–î–ï–°–¨
    
    # Labels = input_ids –¥–ª—è sequence-to-sequence
    if 'input_ids' in inputs:
        inputs['labels'] = inputs['input_ids'].clone()
    
    return inputs
```

### –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º—ã

1. **–ß—Ç–æ —Ç–∞–∫–æ–µ `self.processor`:**
   - `AutoProcessor.from_pretrained()` –¥–ª—è DeepSeek-OCR –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `LlamaTokenizerFast`
   - –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ tokenizer, –Ω–µ processor —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π images

2. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ processor:**
   ```python
   processor = AutoProcessor.from_pretrained('deepseek-ai/DeepSeek-OCR', ...)
   type(processor)  # <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>
   hasattr(processor, 'image_processor')  # False
   hasattr(processor, 'tokenizer')  # False
   ```

3. **–ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ inference:**
   –í `test_inference.py` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:
   ```python
   inputs = processor(images=image, return_tensors="pt")  # –¢–æ–ª—å–∫–æ images, –±–µ–∑ text
   ```
   –≠—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è inference (–±–µ–∑ text).

4. **–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:**
   –î–ª—è –æ–±—É—á–µ–Ω–∏—è Vision2Seq –º–æ–¥–µ–ª–∏ –Ω—É–∂–µ–Ω —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å:
   - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Üí pixel_values
   - –¢–µ–∫—Å—Ç ‚Üí input_ids, attention_mask
   - Labels ‚Üí –¥–ª—è loss

### –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

#### –í–∞—Ä–∏–∞–Ω—Ç 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ image_processor –∏ tokenizer

–ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏, –∫–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å image_processor –æ—Ç–¥–µ–ª—å–Ω–æ. –í–æ–∑–º–æ–∂–Ω–æ:
```python
from transformers import AutoImageProcessor, AutoTokenizer

image_processor = AutoImageProcessor.from_pretrained(...)
tokenizer = AutoTokenizer.from_pretrained(...)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
pixel_values = image_processor(images, return_tensors="pt")
text_inputs = tokenizer(texts, return_tensors="pt", padding=True)
```

#### –í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å processor —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, tokenizer –¥–ª—è —Ç–µ–∫—Å—Ç–∞

–ï—Å–ª–∏ processor –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ images:
```python
pixel_values = self.processor(images=images, return_tensors="pt")
text_inputs = self.processor.tokenizer(texts, return_tensors="pt", padding=True)
```

#### –í–∞—Ä–∏–∞–Ω—Ç 3: –ò–∑—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é DeepSeek-OCR

–í–æ–∑–º–æ–∂–Ω–æ, –µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –æ–±—É—á–µ–Ω–∏—è DeepSeek-OCR –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ API.

### –ß—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å

1. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `AutoProcessor.from_pretrained()` –¥–ª—è DeepSeek-OCR
2. ‚ùì –ï—Å—Ç—å –ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–π `AutoImageProcessor` –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏?
3. ‚ùì –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Vision2Seq –º–æ–¥–µ–ª–µ–π?
4. ‚ùì –ï—Å—Ç—å –ª–∏ –ø—Ä–∏–º–µ—Ä—ã –æ–±—É—á–µ–Ω–∏—è DeepSeek-OCR –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ HuggingFace?

---

## üìÅ –ò–ó–ú–ï–ù–Å–ù–ù–´–ï –§–ê–ô–õ–´

### 1. `utils/trainer.py`
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç `from tqdm import tqdm`
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω progress bar –≤ `load_model_and_processor()`
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω progress bar –≤ `prepare_datasets()`
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω `disable_tqdm=False` –≤ `TrainingArguments`
- ‚úÖ –£–¥–∞–ª—ë–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä `optimizer` –∏–∑ `TrainingArguments`
- ‚úÖ –°–æ–∑–¥–∞–Ω –º–µ—Ç–æ–¥ `_data_collator()` (–ø–µ—Ä–µ–Ω–µ—Å—ë–Ω –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏)
- ‚ùå `_data_collator()` –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å processor API

### 2. `scripts/train_lora.py`
- ‚úÖ –£–ª—É—á—à–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π —à–∞–≥–æ–≤
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —à–∞–≥–æ–≤

### 3. `configs/training_config.yaml`
- ‚úÖ –ò–∑–º–µ–Ω—ë–Ω `dataloader_num_workers: 2` ‚Üí `dataloader_num_workers: 0`

### 4. `PROGRESS_INDICATOR_REPORT.md`
- ‚úÖ –°–æ–∑–¥–∞–Ω –æ—Ç—á—ë—Ç –æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ progress bars

---

## üß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

### ‚úÖ –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:

1. **Progress bars –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:**
   ```
   –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞:   0%|                                | 0/2 [00:00<?]
   –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞:  50%|####################            | 1/2 [00:01<00:01]
   –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~5-30 –º–∏–Ω, –µ—Å–ª–∏ —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è): 100%|####| 2/2 [00:10<00:00]
   ```

2. **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–æ:**
   ```
   ================================================================================
   –®–∞–≥ 1/5: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...
   ================================================================================
   OK –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à—ë–Ω
   
   ================================================================================
   –®–∞–≥ 2/5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA...
   ================================================================================
   ```

3. **–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ:**
   - –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
   - –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è (10-14 —Å–µ–∫—É–Ω–¥)
   - LoRA –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è
   - –î–∞—Ç–∞—Å–µ—Ç—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è

4. **Trainer —Å–æ–∑–¥–∞—ë—Ç—Å—è —É—Å–ø–µ—à–Ω–æ:**
   - TrainingArguments —Å–æ–∑–¥–∞—é—Ç—Å—è
   - Trainer –æ–±—ä–µ–∫—Ç —Å–æ–∑–¥–∞—ë—Ç—Å—è

### ‚ùå –ß—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:

1. **–û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è:**
   - –û—à–∏–±–∫–∞ –≤ `_data_collator()` –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
   - Processor –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä `images` –≤–º–µ—Å—Ç–µ —Å `text`

---

## üìä –õ–û–ì–ò –û–®–ò–ë–ö–ò

```
2026-01-10 16:08:07 - train_lora - ERROR - –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'images'
Traceback (most recent call last):
  File "C:\DSOCR-HW\utils\trainer.py", line 338, in train
    self.trainer.train()
  File "C:\DSOCR-HW\venv\lib\site-packages\transformers\trainer.py", line 2052, in train
    return inner_training_loop(
  File "C:\DSOCR-HW\venv\lib\site-packages\transformers\trainer.py", line 2345, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "C:\DSOCR-HW\venv\lib\site-packages\accelerate\data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "C:\DSOCR-HW\venv\lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
    data = self._next_data()
  File "C:\DSOCR-HW\venv\lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\DSOCR-HW\venv\lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "C:\DSOCR-HW\utils\trainer.py", line 206, in _data_collator
    inputs = self.processor(images=images, text=texts, return_tensors="pt", padding=True)
  File "C:\DSOCR-HW\venv\lib\site-packages\transformers\tokenization_utils_base.py", line 3024, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "C:\DSOCR-HW\venv\md\venv\lib\site-packages\transformers\tokenization_utils_base.py", line 3112, in _call_one
    return self.batch_encode_plus(
  File "C:\DSOCR-HW\venv\lib\site-packages\transformers\tokenization_utils_base.py", line 3314, in batch_encode_plus
    return self._batch_encode_plus(
TypeError: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'images'
```

---

## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –°–ï–ú–Å–ù–ê (Tech Lead)

–°—ë–º–∞, –ø—Ä–∏–≤–µ—Ç!

–ö–∞–∫ –≤–∏–¥–∏—à—å, progress bars —Ä–∞–±–æ—Ç–∞—é—Ç –æ—Ç–ª–∏—á–Ω–æ ‚Äî –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ª–æ–≥–∏ —Å—Ç–∞–ª–∏ –Ω–∞–º–Ω–æ–≥–æ –ø–æ–Ω—è—Ç–Ω–µ–µ. –ù–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å API processor –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

**–ü—Ä–æ–±–ª–µ–º–∞:** `AutoProcessor.from_pretrained()` –¥–ª—è DeepSeek-OCR –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ `LlamaTokenizerFast`, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä `images`. –î–ª—è inference —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç (—Ç–æ–ª—å–∫–æ images), –Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω—É–∂–Ω—ã –∏ images, –∏ text.

**–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**
1. –ù–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è DeepSeek-OCR
2. –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π `AutoImageProcessor` –∏ `AutoTokenizer`
3. –ò–ª–∏ –Ω–∞–π—Ç–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π processor –¥–ª—è Vision2Seq –º–æ–¥–µ–ª–µ–π

**–í–æ–ø—Ä–æ—Å—ã:**
- –ï—Å—Ç—å –ª–∏ —É —Ç–µ–±—è –ø—Ä–∏–º–µ—Ä—ã –æ–±—É—á–µ–Ω–∏—è Vision2Seq –º–æ–¥–µ–ª–µ–π —Å HuggingFace?
- –ó–Ω–∞–µ—à—å –ª–∏ —Ç—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –¥–ª—è DeepSeek-OCR training?
- –ú–æ–∂–µ—Ç –±—ã—Ç—å, –µ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ DeepSeek-OCR?

–ü–æ–∫–∞ —á—Ç–æ —è –∑–∞–∫–æ–º–º–∏—Ç–∏–ª –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (progress bars —Ä–∞–±–æ—Ç–∞—é—Ç), –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ —Å data_collator. –ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Ä–∞–∑–±–µ—Ä—ë–º—Å—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º API, –æ–±—É—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å.

P.S. –í—Å–µ progress bars —Ä–∞–±–æ—Ç–∞—é—Ç –∫—Ä–∞—Å–∏–≤–æ ‚Äî —Ç–µ–ø–µ—Ä—å –≤–∏–¥–Ω–æ, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –∂–∏–≤ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç! üéâ

---

## üìù –ß–ï–ö–õ–ò–°–¢

- [x] –î–æ–±–∞–≤–ª–µ–Ω—ã progress bars –≤ `load_model_and_processor()`
- [x] –î–æ–±–∞–≤–ª–µ–Ω—ã progress bars –≤ `prepare_datasets()`
- [x] –í–∫–ª—é—á—ë–Ω progress bar –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (`disable_tqdm=False`)
- [x] –£–ª—É—á—à–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ `train_lora.py`
- [x] –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `optimizer`
- [x] –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å pickle –∏ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
- [x] –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å multiprocessing (Windows + custom code)
- [ ] **–ù–£–ñ–ù–û:** –ò—Å–ø—Ä–∞–≤–∏—Ç—å `_data_collator()` –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ API processor

---

## üöÄ –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

1. **–°–µ–º—ë–Ω (Tech Lead):**
   - –ò–∑—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –¥–ª—è –æ–±—É—á–µ–Ω–∏—è DeepSeek-OCR
   - –ù–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

2. **–ù–∏–∫–æ–ª–∞–π:**
   - –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç –°–µ–º—ë–Ω–∞ - –∏—Å–ø—Ä–∞–≤–∏—Ç—å `_data_collator()`
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ
   - –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ progress bars —Ä–∞–±–æ—Ç–∞—é—Ç –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

---

**–° —É–≤–∞–∂–µ–Ω–∏–µ–º –∏ –Ω–∞–¥–µ–∂–¥–æ–π –Ω–∞ –ø–æ–º–æ—â—å,**  
**–ù–∏–∫–æ–ª–∞–π (Cursor AI)** üéØ
