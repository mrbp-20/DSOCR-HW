# üöÄ –ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ù–ò–ö–û–õ–ê–Ø: –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø LoRA

**–û—Ç:** –°–µ–º—ë–Ω (Tech Lead)  
**–ö–æ–º—É:** –ù–∏–∫–æ–ª–∞–π (Cursor AI Senior ML Engineer)  
**–î–∞—Ç–∞:** 09.01.2026, 22:37 MSK  
**–¢–µ–º–∞:** –ó–∞–ø—É—Å–∫ –ø–µ—Ä–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è LoRA –Ω–∞ —Ä—É–∫–æ–ø–∏—Å–Ω–æ–º –ø–æ—á–µ—Ä–∫–µ  
**Issue:** #2  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** CRITICAL  
**–°—Ä–æ–∫:** 5-10 –º–∏–Ω—É—Ç (+ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è)

---

## üéØ –¶–ï–õ–¨

–ó–∞–ø—É—Å—Ç–∏—Ç—å **–ø–µ—Ä–≤–æ–µ proof-of-concept –æ–±—É—á–µ–Ω–∏–µ** LoRA –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –í–ª–∞–¥–∏–º–∏—Ä–∞ (4 –æ–±—Ä–∞–∑—Ü–∞, train=3, val=1).

**–ó–∞–¥–∞—á–∏:**
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å—ë –≥–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É
2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
3. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
5. –ó–∞–∫–æ–º–º–∏—Ç–∏—Ç—å –≤ Git

---

## üìä –ö–û–ù–¢–ï–ö–°–¢

**–ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–Ω–æ (Issue #5):**
- ‚úÖ –î–∞–Ω–Ω—ã–µ –í–ª–∞–¥–∏–º–∏—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
- ‚úÖ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω (train=3, val=1)
- ‚úÖ `data/processed/train/` –∏ `data/processed/val/` –≥–æ—Ç–æ–≤—ã
- ‚úÖ Metadata.json —Å–æ–∑–¥–∞–Ω—ã

**–ß—Ç–æ —Å–µ–π—á–∞—Å:**
- üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ!

---

## ‚úÖ –®–ê–ì–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø

### –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏

```powershell
cd C:\DSOCR-HW
.\venv\Scripts\Activate.ps1

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
ls data/processed/train/images/
ls data/processed/val/images/

# –ü—Ä–æ–≤–µ—Ä—è–µ–º metadata
cat data/processed/train/metadata.json
cat data/processed/val/metadata.json
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- `train/images/` —Å–æ–¥–µ—Ä–∂–∏—Ç 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `val/images/` —Å–æ–¥–µ—Ä–∂–∏—Ç 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- Metadata.json —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π JSON

---

### –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```powershell
cat configs/training_config.yaml
```

**–ü—Ä–æ–≤–µ—Ä—å –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `model_name_or_path`: –ø—É—Ç—å –∫ DeepSeek-VL2-Tiny
- `train_data_dir`: `data/processed/train`
- `val_data_dir`: `data/processed/val`
- `output_dir`: `outputs/lora_checkpoints`
- `num_train_epochs`: 3-5 (–¥–ª—è proof-of-concept)
- `per_device_train_batch_size`: 1 (–∏–∑-–∑–∞ –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö)

**–ï—Å–ª–∏ –Ω—É–∂–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- –£–º–µ–Ω—å—à–∏ `num_train_epochs` –¥–æ 3 (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞)
- –£–±–µ–¥–∏—Å—å, —á—Ç–æ `per_device_train_batch_size: 1`

---

### –®–∞–≥ 3: –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø! üöÄ

```powershell
python scripts/train_lora.py --config configs/training_config.yaml
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ (–µ—Å–ª–∏ –µ—Å—Ç—å wrapper-—Å–∫—Ä–∏–ø—Ç):**
```powershell
python train_lora.py
```

**–ò–ª–∏ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å:**
```powershell
python -m scripts.train_lora --config configs/training_config.yaml
```

---

### –®–∞–≥ 4: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
2026-01-09 22:XX:XX - train_lora - INFO - –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ DeepSeek-VL2-Tiny...
2026-01-09 22:XX:XX - train_lora - INFO - –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: XXX M
2026-01-09 22:XX:XX - train_lora - INFO - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA (rank=8, alpha=16)...
2026-01-09 22:XX:XX - train_lora - INFO - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö: train=3, val=1
2026-01-09 22:XX:XX - train_lora - INFO - –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...

Epoch 1/3:
  Step 1/3: loss=X.XXX
  Step 2/3: loss=X.XXX
  Step 3/3: loss=X.XXX
  Validation loss: X.XXX

Epoch 2/3:
  ...
```

**–°–ª–µ–¥–∏ –∑–∞:**
- ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- ‚úÖ LoRA –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- ‚úÖ –î–∞–Ω–Ω—ã–µ —á–∏—Ç–∞—é—Ç—Å—è (train=3, val=1)
- ‚úÖ Loss —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è —Å —ç–ø–æ—Ö–∞–º–∏
- ‚úÖ –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è

---

### –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è:**

```powershell
# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç—ã
ls outputs/lora_checkpoints/

# –î–æ–ª–∂–Ω—ã –±—ã—Ç—å:
# - checkpoint-final/ (–∏–ª–∏ checkpoint-last/)
# - adapter_config.json
# - adapter_model.safetensors (LoRA –≤–µ—Å–∞)
# - training_args.bin
# - training_log.txt (–∏–ª–∏ trainer_state.json)
```

**–ü—Ä–æ–≤–µ—Ä—å:**
- [ ] –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ–∑–¥–∞–Ω
- [ ] `adapter_model.safetensors` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (—Ä–∞–∑–º–µ—Ä > 0 MB)
- [ ] –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã

---

### –®–∞–≥ 6: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏

–°–æ–∑–¥–∞–π —Ñ–∞–π–ª `REPORT_TRAINING_20260109.md` —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:

```markdown
# üéñÔ∏è –û—Ç—á—ë—Ç –æ –ø–µ—Ä–≤–æ–º –æ–±—É—á–µ–Ω–∏–∏ LoRA

**–î–∞—Ç–∞:** 09.01.2026, XX:XX MSK  
**–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å:** –ù–∏–∫–æ–ª–∞–π  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ / ‚ùå / ‚ö†Ô∏è

## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

- **–ú–æ–¥–µ–ª—å:** DeepSeek-VL2-Tiny
- **–î–∞–Ω–Ω—ã–µ:** Train=3, Val=1
- **–≠–ø–æ—Ö–∏:** X
- **Batch size:** 1
- **LoRA rank:** 8
- **LoRA alpha:** 16
- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** XX –º–∏–Ω

## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### Loss –ø–æ —ç–ø–æ—Ö–∞–º:

- Epoch 1: train_loss=X.XXX, val_loss=X.XXX
- Epoch 2: train_loss=X.XXX, val_loss=X.XXX
- Epoch 3: train_loss=X.XXX, val_loss=X.XXX

### –§–∞–π–ª—ã:

- –ß–µ–∫–ø–æ–∏–Ω—Ç: `outputs/lora_checkpoints/checkpoint-final/`
- LoRA –≤–µ—Å–∞: `adapter_model.safetensors` (XX MB)

## –ü—Ä–æ–±–ª–µ–º—ã / –ù–∞–±–ª—é–¥–µ–Ω–∏—è

[–û–ø–∏—à–∏ –ª—é–±—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ –≤–∞–∂–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è]

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
2. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ (20-50 —Å—Ç—Ä–æ–∫)
3. –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö
```

---

### –®–∞–≥ 7: –ó–∞–∫–æ–º–º–∏—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

```powershell
# –î–æ–±–∞–≤–ª—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç—ã (–±–µ–∑ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ > 100 MB)
git add outputs/lora_checkpoints/checkpoint-final/adapter_config.json
git add outputs/lora_checkpoints/checkpoint-final/adapter_model.safetensors
git add outputs/lora_checkpoints/checkpoint-final/training_args.bin

# –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—á—ë—Ç
git add REPORT_TRAINING_20260109.md

git commit -m "feat: complete first LoRA training (train=3, val=1, epochs=X)"
git push origin main
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ï—Å–ª–∏ `adapter_model.safetensors` > 100 MB, –Ω–µ –∫–æ–º–º–∏—Ç—å –µ–≥–æ –≤ Git. –ò—Å–ø–æ–ª—å–∑—É–π Git LFS –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏ –ª–æ–∫–∞–ª—å–Ω–æ.

---

### –®–∞–≥ 8: –û–±–Ω–æ–≤–∏—Ç—å Issue #2

–î–æ–±–∞–≤—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –≤ Issue #2:

```markdown
## ‚úÖ –ü–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!

**–î–∞—Ç–∞:** 09.01.2026, XX:XX MSK  
**–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** XX –º–∏–Ω

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
- Train: 3 –æ–±—Ä–∞–∑—Ü–∞
- Val: 1 –æ–±—Ä–∞–∑–µ—Ü
- –≠–ø–æ—Ö–∏: X
- Final loss: X.XXX

### –†–µ–∑—É–ª—å—Ç–∞—Ç:
- ‚úÖ LoRA –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: `outputs/lora_checkpoints/`
- ‚úÖ –û—Ç—á—ë—Ç: `REPORT_TRAINING_20260109.md`

### –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:
üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö!
```

---

## üö® –ï–°–õ–ò –í–û–ó–ù–ò–ö–õ–ò –ü–†–û–ë–õ–ï–ú–´

### –ü—Ä–æ–±–ª–µ–º–∞ 1: "CUDA out of memory"

**–†–µ—à–µ–Ω–∏–µ:**
```yaml
# –í configs/training_config.yaml
per_device_train_batch_size: 1
gradient_accumulation_steps: 1
```

–ò–ª–∏ –∑–∞–ø—É—Å–∫–∞–π —Å CPU (for debugging):
```powershell
python scripts/train_lora.py --config configs/training_config.yaml --device cpu
```

---

### –ü—Ä–æ–±–ª–µ–º–∞ 2: "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

**–ü—Ä–æ–≤–µ—Ä—å –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏:**
```powershell
ls C:/Models/deepseek-ai/deepseek-vl2-tiny
```

–ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç ‚Äî —Å–∫–∞—á–∞–π –µ—ë –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π HuggingFace ID:
```yaml
model_name_or_path: "deepseek-ai/deepseek-vl2-tiny"
```

---

### –ü—Ä–æ–±–ª–µ–º–∞ 3: "–î–∞–Ω–Ω—ã–µ –Ω–µ —á–∏—Ç–∞—é—Ç—Å—è"

**–ü—Ä–æ–≤–µ—Ä—å metadata.json:**
```powershell
cat data/processed/train/metadata.json
```

–î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π JSON —Å –ø–æ–ª—è–º–∏: `image_path`, `transcription`

---

### –ü—Ä–æ–±–ª–µ–º–∞ 4: "–û–±—É—á–µ–Ω–∏–µ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è"

**–ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏:**
```powershell
cat outputs/lora_checkpoints/training_log.txt
```

–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –Ω–µ –ø–æ–Ω—è—Ç–Ω–∞ ‚Äî —Å–∫–æ–ø–∏—Ä—É–π –µ—ë –≤ –æ—Ç—á—ë—Ç –∏ –Ω–∞–ø–∏—à–∏ –°—ë–º–µ.

---

## üìä –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´

**–ü—Ä–∏ 4 –æ–±—Ä–∞–∑—Ü–∞—Ö (proof-of-concept):**

- ‚ö†Ô∏è Loss –º–æ–∂–µ—Ç –Ω–µ —É–º–µ–Ω—å—à–∏—Ç—å—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)
- ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç "–ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è" (overfitting)
- ‚úÖ –ù–æ –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–ª–∂–µ–Ω –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è —É—Å–ø–µ—à–Ω–æ
- ‚úÖ –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ–∑–¥–∞—Ç—å—Å—è

**–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ!** –¶–µ–ª—å ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç.

---

## üéØ –ì–õ–ê–í–ù–ê–Ø –¶–ï–õ–¨

‚úÖ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ  
‚úÖ –ü–æ–ª—É—á–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç —Å LoRA –≤–µ—Å–∞–º–∏  
‚úÖ –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç  
‚úÖ –°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç  
‚úÖ –ó–∞–∫–æ–º–º–∏—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã  

---

## üìù –ß–ï–ö–õ–ò–°–¢

- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- [ ] –ó–∞–ø—É—â–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ
- [ ] –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
- [ ] –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ–∑–¥–∞–Ω—ã
- [ ] –û—Ç—á—ë—Ç `REPORT_TRAINING_20260109.md` —Å–æ–∑–¥–∞–Ω
- [ ] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–∫–æ–º–º–∏—á–µ–Ω—ã
- [ ] Issue #2 –æ–±–Ω–æ–≤–ª–µ–Ω

---

## üí¨ –ü–û–°–õ–ï –í–´–ü–û–õ–ù–ï–ù–ò–Ø

–ù–∞–ø–∏—à–∏ –≤ Issue #2:
> "–°—ë–º–∞, –ø–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! LoRA –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –û—Ç—á—ë—Ç –≥–æ—Ç–æ–≤."

–ò –¥–∞–π –∑–Ω–∞—Ç—å –í–ª–∞–¥–∏–º–∏—Ä—É, —á—Ç–æ –º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å!

---

**–ù–∏–∫–æ–ª–∞–π, –Ω–∞ —Å—Ç–∞—Ä—Ç! –≠—Ç–æ –≥–ª–∞–≤–Ω—ã–π –º–æ–º–µ–Ω—Ç!** üöÄüî•

**–í—Ä–µ–º—è:** ~5-15 –º–∏–Ω (–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞) + XX –º–∏–Ω (–æ–±—É—á–µ–Ω–∏–µ)  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** CRITICAL üî¥  

---

**–° –≤–µ—Ä–æ–π –≤ —Ç–≤–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º,**  
**–°–µ–º—ë–Ω (Tech Lead, –∫–æ—Ç–æ—Ä—ã–π —Ç–µ–ø–µ—Ä—å –≤–Ω–∏–º–∞—Ç–µ–ª–µ–Ω)** üí™üî•
